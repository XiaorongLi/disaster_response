{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database \n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xiaorong/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/xiaorong/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/xiaorong/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import xgboost as xgb \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import mlsmote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///messages.db')\n",
    "conn = engine.connect()\n",
    "df = pd.read_sql('SELECT * FROM messages', con=conn)\n",
    "df.head()\n",
    "df.drop(['child_alone'], axis = 1, inplace = True) # This is because no sample has l for label 'child_alone', all 0's.\n",
    "X = df['message']\n",
    "Y = df.iloc[:, 4: ]\n",
    "#X = X.iloc[:10000] # memory problems\n",
    "#Y = Y.iloc[:10000, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenization function to process text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''Function normalizes case, removes punctuation, stems, lemmatizes and parse a message into separate words.\n",
    "    '''\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Machine learning model\n",
    "Since we are dealing with a multi-label problem, [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) is used.\n",
    "All the messages are first turned into tf-idf matrix, without differentiating between training or testing part. This is necessary in current work flow. Otherwise, if we first split between training and testing data, then convert them respectively into tf-idf matrices, they will for sure have different number of columns, because the two parts are extremely likely to have different distributions of words! However, this seemed not to be an issue when I used pipeline previously. Not clear why this is the case. Need to dive deeper later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.3) #train_size is kept small for memory reason.\n",
    "\n",
    "vect = CountVectorizer(tokenizer=tokenize)\n",
    "tfidf = TfidfTransformer()\n",
    "X_counts = vect.fit_transform(X)\n",
    "X_tfidf = tfidf.fit_transform(X_counts).toarray()\n",
    "\n",
    "X_tfidf = pd.DataFrame(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_tfidf, Xtest_tfidf, Ytrain, Ytest = train_test_split(X_tfidf, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain_tfidf.index = Xtrain.index  \n",
    "# Since now the data is first transformed into tfidf matrix and then split, this step is not needed any more.\n",
    "# This is extremely important!! don't forget that tfidftransformer reset the index of its output. If we don't keep\n",
    "# Xtrain_tfidf's index in consistancy with Xtrain/Ytrain, the relationship between the Xtrain_tfidf and Ytrain is \n",
    "# completely destroyed! They are sent to fit the classifier later.\n",
    "# A direct consequence if this step is not executed is that, in the next cell, X_sub and Ysub will have different\n",
    "# number of rows. This is figured out by looking at the source code of get_minority_instace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mlsmote to generate more minority instances\n",
    "X_sub, Y_sub = mlsmote.get_minority_instace(Xtrain_tfidf, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res,Y_res =mlsmote.MLSMOTE(X_sub, Y_sub, 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19661, 31967)\n",
      "(19661, 35)\n",
      "(2111, 31967) (2111, 35)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain_tfidf.shape)\n",
    "print(Ytrain.shape)\n",
    "print(X_sub.shape, Y_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2111  minor instances found in the data.\n",
      "10111  minor instances generated with mlsmote.\n",
      "10111\n"
     ]
    }
   ],
   "source": [
    "print(X_sub.shape[0], ' minor instances found in the data.')\n",
    "print(X_res.shape[0], ' minor instances generated with mlsmote.')\n",
    "print(Y_res.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLSMOTE once more\n",
    "#X_sub1, Y_sub1 = mlsmote.get_minority_instace(X_res, Y_res)\n",
    "#X_res1,Y_res1 =mlsmote.MLSMOTE(X_sub1, Y_sub1, 1000)\n",
    "#print(X_sub1.shape[0], ' minor instances found in the data.')\n",
    "#print(X_res1.shape[0], ' minor instances generated with mlsmote.')\n",
    "#print(Y_res1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_sub2, Y_sub2 = mlsmote.get_minority_instace(X_res1, Y_res1)\n",
    "#X_res2,Y_res2 =mlsmote.MLSMOTE(X_sub2, Y_sub2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_sub2.shape[0], ' minor instances found in the data.')\n",
    "#print(X_res2.shape[0], ' minor instances generated with mlsmote.')\n",
    "#print(Y_res2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the new generated minority-class instances with the original train data\n",
    "Xtrain_tfidf = Xtrain_tfidf.append(X_res)\n",
    "Ytrain = Ytrain.append(Y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29772, 31967)\n",
      "(29772, 35)\n"
     ]
    }
   ],
   "source": [
    "# check dimensions again\n",
    "print(Xtrain_tfidf.shape)\n",
    "print(Ytrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#    ('tfidf', TfidfTransformer()),\n",
    "#    ('clf', MultiOutputClassifier(estimator=RandomForestClassifier(n_estimators=10, max_depth=5, \\\n",
    "#                                                                   max_features=0.4)))\n",
    "#])\n",
    "\n",
    "#pipeline.get_params()\n",
    "#pipeline.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaorong/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/xiaorong/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:546: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=RandomForestClassifier(max_depth=8,\n",
       "                                                       max_features=0.4,\n",
       "                                                       n_estimators=30,\n",
       "                                                       oob_score=True))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultiOutputClassifier(estimator=RandomForestClassifier(oob_score=True, n_estimators=30, \\\n",
    "                                                             max_depth = 8, max_features = 0.4))\n",
    "clf.fit(Xtrain_tfidf, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6554, 35)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_tfidf.shape\n",
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaorong/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/xiaorong/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# check performance on train data\n",
    "Ytrain_pred = clf.predict(Xtrain_tfidf)\n",
    "report_train = classification_report(Ytrain, Ytrain_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92     25156\n",
      "           1       0.89      0.43      0.58      5297\n",
      "           2       1.00      0.24      0.38       231\n",
      "           3       0.85      0.59      0.69     16845\n",
      "           4       0.87      0.33      0.48      2598\n",
      "           5       0.89      0.41      0.56      2111\n",
      "           6       0.97      0.17      0.28       938\n",
      "           7       0.98      0.26      0.41      1211\n",
      "           8       0.88      0.33      0.48      1016\n",
      "           9       0.86      0.61      0.71      2045\n",
      "          10       0.81      0.77      0.79      3932\n",
      "          11       0.84      0.54      0.66      3282\n",
      "          12       0.95      0.72      0.82      1560\n",
      "          13       1.00      0.25      0.40       593\n",
      "          14       0.91      0.43      0.58       865\n",
      "          15       0.87      0.36      0.51      1119\n",
      "          16       0.89      0.56      0.69      1755\n",
      "          17       0.95      0.14      0.25      4367\n",
      "          18       0.98      0.23      0.37      3652\n",
      "          19       0.91      0.35      0.51      1708\n",
      "          20       0.96      0.36      0.52      1723\n",
      "          21       0.83      0.69      0.75      1861\n",
      "          22       1.00      0.17      0.29       268\n",
      "          23       0.99      0.41      0.58       687\n",
      "          24       1.00      0.23      0.37       230\n",
      "          25       0.99      0.32      0.48       723\n",
      "          26       1.00      0.16      0.28      1389\n",
      "          27       0.91      0.51      0.66     11998\n",
      "          28       0.89      0.57      0.69      2818\n",
      "          29       0.80      0.69      0.74      3121\n",
      "          30       0.84      0.69      0.75       802\n",
      "          31       0.85      0.78      0.81      2805\n",
      "          32       0.85      0.73      0.79      1941\n",
      "          33       0.96      0.21      0.35      1558\n",
      "          34       0.86      0.32      0.46      6083\n",
      "\n",
      "   micro avg       0.87      0.59      0.70    118288\n",
      "   macro avg       0.91      0.44      0.56    118288\n",
      "weighted avg       0.88      0.59      0.67    118288\n",
      " samples avg       0.78      0.56      0.61    118288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on test data\n",
    "Ytest_pred = clf.predict(Xtest_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaorong/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/xiaorong/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/xiaorong/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(Ytest, Ytest_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88      5048\n",
      "           1       0.81      0.42      0.56      1140\n",
      "           2       0.00      0.00      0.00        31\n",
      "           3       0.73      0.55      0.63      2744\n",
      "           4       0.65      0.19      0.30       526\n",
      "           5       0.69      0.24      0.35       340\n",
      "           6       0.89      0.10      0.17       177\n",
      "           7       0.50      0.02      0.03       120\n",
      "           8       0.56      0.14      0.23       211\n",
      "           9       0.80      0.59      0.68       398\n",
      "          10       0.80      0.77      0.79       753\n",
      "          11       0.82      0.55      0.66       598\n",
      "          12       0.77      0.64      0.70       104\n",
      "          13       0.57      0.05      0.09       157\n",
      "          14       0.75      0.21      0.33        72\n",
      "          15       0.58      0.21      0.31       225\n",
      "          16       0.71      0.47      0.56       286\n",
      "          17       0.65      0.06      0.11       883\n",
      "          18       0.56      0.06      0.11       439\n",
      "          19       0.62      0.19      0.29       300\n",
      "          20       0.79      0.20      0.32       348\n",
      "          21       0.46      0.58      0.51       143\n",
      "          22       0.00      0.00      0.00        40\n",
      "          23       0.38      0.06      0.11        79\n",
      "          24       0.00      0.00      0.00        28\n",
      "          25       0.70      0.08      0.15        86\n",
      "          26       0.67      0.01      0.01       285\n",
      "          27       0.85      0.59      0.69      1789\n",
      "          28       0.90      0.53      0.66       527\n",
      "          29       0.73      0.60      0.66       616\n",
      "          30       0.64      0.42      0.50        72\n",
      "          31       0.89      0.85      0.87       594\n",
      "          32       0.48      0.57      0.52       122\n",
      "          33       0.57      0.05      0.09       331\n",
      "          34       0.79      0.31      0.45      1320\n",
      "\n",
      "   micro avg       0.78      0.56      0.65     20932\n",
      "   macro avg       0.63      0.32      0.38     20932\n",
      "weighted avg       0.75      0.56      0.59     20932\n",
      " samples avg       0.69      0.51      0.54     20932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Below are some historical results that are a bit obscure but I still don't want to delete yet. Readers may stop here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.10      0.17      1547\n",
      "          1       0.78      0.99      0.87      5007\n",
      "\n",
      "avg / total       0.77      0.78      0.71      6554\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.78      0.99      0.87      5007\n",
      "               request       0.81      0.38      0.52      1077\n",
      "                 offer       0.00      0.00      0.00        34\n",
      "           aid_related       0.72      0.52      0.60      2694\n",
      "          medical_help       0.57      0.15      0.24       512\n",
      "      medical_products       0.78      0.22      0.34       353\n",
      "     search_and_rescue       0.64      0.16      0.26       178\n",
      "              security       0.00      0.00      0.00       103\n",
      "              military       0.66      0.12      0.20       225\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.78      0.56      0.65       445\n",
      "                  food       0.77      0.78      0.77       722\n",
      "               shelter       0.81      0.45      0.58       561\n",
      "              clothing       0.77      0.49      0.60        97\n",
      "                 money       0.57      0.15      0.24       140\n",
      "        missing_people       0.80      0.29      0.42        84\n",
      "              refugees       0.63      0.26      0.37       208\n",
      "                 death       0.77      0.47      0.59       322\n",
      "             other_aid       0.75      0.05      0.09       867\n",
      "infrastructure_related       0.29      0.00      0.01       419\n",
      "             transport       0.65      0.27      0.38       298\n",
      "             buildings       0.78      0.22      0.35       310\n",
      "           electricity       0.71      0.21      0.32       143\n",
      "                 tools       0.00      0.00      0.00        34\n",
      "             hospitals       0.50      0.01      0.03        69\n",
      "                 shops       0.00      0.00      0.00        21\n",
      "           aid_centers       0.33      0.01      0.03        69\n",
      "  other_infrastructure       0.14      0.00      0.01       300\n",
      "       weather_related       0.88      0.45      0.60      1790\n",
      "                floods       0.91      0.52      0.66       562\n",
      "                 storm       0.77      0.57      0.66       633\n",
      "                  fire       0.57      0.25      0.35        63\n",
      "            earthquake       0.88      0.79      0.84       573\n",
      "                  cold       0.67      0.35      0.46       136\n",
      "         other_weather       0.61      0.10      0.17       342\n",
      "         direct_report       0.74      0.29      0.42      1244\n",
      "\n",
      "           avg / total       0.74      0.53      0.57     20635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n"
     ]
    }
   ],
   "source": [
    "r1 = classification_report(Ytest.iloc[:,0], Ypred.iloc[:,0])\n",
    "r1 = classification_report(Ytest['related'], Ypred['related'])\n",
    "\n",
    "report = classification_report(Ytest, Ypred, target_names = Ytest.columns)\n",
    "\n",
    "print(r1)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try cross validation, which is in practice too slow to convey any useful info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, parameter search with CV is way too slow\n",
    "parameters = {\n",
    "    # determine exact parameter names from pipeline.get_params()\n",
    "    'vect__min_df': [0.005, 0.01]\n",
    "    'vect__max_df': [0.25, 0.5, 1.0]\n",
    "    #'clf__estimator__n_estimators': [100, 200],\n",
    "    #'clf__estimator__max_features': ['sqrt', 'log2'],\n",
    "    #'clf__estimator__min_samples_leaf': [10,20]\n",
    "}\n",
    "\n",
    "#cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "#cv.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.39      0.50      1562\n",
      "          1       0.83      0.95      0.89      4992\n",
      "\n",
      "avg / total       0.80      0.81      0.79      6554\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.95      0.89      4992\n",
      "               request       0.83      0.50      0.62      1088\n",
      "                 offer       0.00      0.00      0.00        23\n",
      "           aid_related       0.76      0.70      0.73      2723\n",
      "          medical_help       0.65      0.07      0.12       522\n",
      "      medical_products       0.72      0.11      0.18       312\n",
      "     search_and_rescue       0.77      0.06      0.10       179\n",
      "              security       0.00      0.00      0.00       111\n",
      "              military       0.64      0.08      0.15       220\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.85      0.37      0.52       425\n",
      "                  food       0.81      0.63      0.71       736\n",
      "               shelter       0.86      0.39      0.54       590\n",
      "              clothing       0.62      0.13      0.22        99\n",
      "                 money       0.80      0.03      0.06       139\n",
      "        missing_people       0.00      0.00      0.00        78\n",
      "              refugees       0.50      0.04      0.07       222\n",
      "                 death       0.83      0.16      0.26       280\n",
      "             other_aid       0.51      0.03      0.06       873\n",
      "infrastructure_related       0.33      0.00      0.01       422\n",
      "             transport       0.74      0.06      0.11       289\n",
      "             buildings       0.78      0.12      0.20       338\n",
      "           electricity       1.00      0.04      0.07       131\n",
      "                 tools       0.00      0.00      0.00        38\n",
      "             hospitals       0.00      0.00      0.00        73\n",
      "                 shops       0.00      0.00      0.00        30\n",
      "           aid_centers       0.00      0.00      0.00        70\n",
      "  other_infrastructure       0.29      0.01      0.01       288\n",
      "       weather_related       0.86      0.69      0.76      1791\n",
      "                floods       0.91      0.45      0.60       517\n",
      "                 storm       0.80      0.51      0.62       588\n",
      "                  fire       1.00      0.01      0.03        74\n",
      "            earthquake       0.90      0.80      0.85       606\n",
      "                  cold       0.85      0.09      0.16       121\n",
      "         other_weather       0.65      0.04      0.07       357\n",
      "         direct_report       0.80      0.38      0.51      1228\n",
      "\n",
      "           avg / total       0.76      0.54      0.58     20573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r1oob)\n",
    "print(reportoob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try random forests in XGBoost\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(estimator=xgb.XGBClassifier(objective='binary:logistic', colsample_bynode=0.4,\\\n",
    "                                                             learning_rate=1, max_depth=5, num_parallel_tree=10,\\\n",
    "                                                             subsample=0.8, eval_metric='logloss',\\\n",
    "                                                             use_label_encoder=False)))\n",
    "])\n",
    "##ATTENTION: how does use_label_encoder affect the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...e,\n",
       "       use_label_encoder=False, validate_parameters=None, verbosity=None),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgb.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = 'pickle_XGBRFmodel.pkl'\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(pipeline_xgb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = pipeline_xgb.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.86      0.93      0.89      5014\n",
      "               request       0.75      0.60      0.67      1084\n",
      "                 offer       0.00      0.00      0.00        34\n",
      "           aid_related       0.76      0.70      0.73      2693\n",
      "          medical_help       0.59      0.34      0.43       524\n",
      "      medical_products       0.67      0.39      0.49       340\n",
      "     search_and_rescue       0.57      0.22      0.32       162\n",
      "              security       0.15      0.02      0.03       104\n",
      "              military       0.62      0.41      0.50       205\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.77      0.67      0.71       414\n",
      "                  food       0.81      0.76      0.78       693\n",
      "               shelter       0.75      0.60      0.67       606\n",
      "              clothing       0.76      0.46      0.57       112\n",
      "                 money       0.52      0.35      0.42       164\n",
      "        missing_people       0.52      0.17      0.26        63\n",
      "              refugees       0.57      0.29      0.38       226\n",
      "                 death       0.75      0.55      0.64       308\n",
      "             other_aid       0.54      0.24      0.33       884\n",
      "infrastructure_related       0.36      0.11      0.17       431\n",
      "             transport       0.68      0.27      0.39       298\n",
      "             buildings       0.67      0.44      0.53       339\n",
      "           electricity       0.56      0.28      0.37       129\n",
      "                 tools       0.33      0.03      0.05        40\n",
      "             hospitals       0.28      0.08      0.12        64\n",
      "                 shops       0.20      0.04      0.06        27\n",
      "           aid_centers       0.38      0.10      0.16        78\n",
      "  other_infrastructure       0.27      0.09      0.14       296\n",
      "       weather_related       0.84      0.74      0.79      1878\n",
      "                floods       0.83      0.60      0.69       579\n",
      "                 storm       0.77      0.65      0.71       628\n",
      "                  fire       0.52      0.24      0.32        51\n",
      "            earthquake       0.86      0.85      0.85       622\n",
      "                  cold       0.67      0.36      0.47       143\n",
      "         other_weather       0.50      0.20      0.29       361\n",
      "         direct_report       0.69      0.49      0.58      1251\n",
      "\n",
      "           avg / total       0.74      0.63      0.67     20845\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(Ytest, Ypred, target_names = Ytest.columns)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
